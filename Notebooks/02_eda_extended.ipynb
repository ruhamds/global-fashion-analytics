{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data quality and readiness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d64762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Import libraries\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make plots look nice\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_theme(palette=\"pastel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd699fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction_ID           Invoice_ID  Line  Customer_ID  Product_ID Size  \\\n",
      "0               1  INV-US-001-01628272     1        42813        2025    M   \n",
      "1               2  INV-US-001-01628273     1        19756        2794    L   \n",
      "2               3  INV-US-001-01628274     1        20648         272    M   \n",
      "3               4  INV-US-001-01628275     1       256672        2884    P   \n",
      "4               5  INV-US-001-01628275     2       256672        1524   38   \n",
      "\n",
      "    Color  Unit_Price  Quantity                Date  Discount  Line_Total  \\\n",
      "0  YELLOW        36.5         1 2023-01-01 19:46:00       0.4        21.9   \n",
      "1  YELLOW        49.5         2 2023-01-01 12:02:00       0.4        59.4   \n",
      "2    PINK        49.5         1 2023-01-01 16:59:00       0.4        29.7   \n",
      "3    None        25.0         1 2023-01-01 12:46:00       0.4        15.0   \n",
      "4    None        59.0         1 2023-01-01 12:46:00       0.0        59.0   \n",
      "\n",
      "   Store_ID  Employee_ID Currency Currency_Symbol                SKU  \\\n",
      "0         1           11      USD               $  CHCO2025-M-YELLOW   \n",
      "1         1           10      USD               $  MACO2794-L-YELLOW   \n",
      "2         1            5      USD               $     MACO272-M-PINK   \n",
      "3         1            8      USD               $        CHSW2884-P-   \n",
      "4         1            8      USD               $       MAPA1524-38-   \n",
      "\n",
      "  Transaction_Type Payment_Method  Invoice_Total  \n",
      "0             Sale    Credit Card           21.9  \n",
      "1             Sale    Credit Card           59.4  \n",
      "2             Sale           Cash           29.7  \n",
      "3             Sale    Credit Card          133.5  \n",
      "4             Sale    Credit Card          133.5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\724911422.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  transactions = pd.read_sql(\"SELECT TOP 5 * FROM Transactions;\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Step 1.2: Connect to SQL Server and load data\n",
    "conn = pyodbc.connect(\n",
    "    \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "    \"Server=DESKTOP-BTvgd35\\\\SQLEXPRESS;\"   # <-- double backslash is required\n",
    "    \"Database=global sales;\"              # <-- exact DB name, check in SSMS\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")\n",
    "\n",
    "# Example: load transactions\n",
    "transactions = pd.read_sql(\"SELECT TOP 5 * FROM Transactions;\", conn)\n",
    "print(transactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba09b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\3735338869.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  transactions = pd.read_sql(\"SELECT * FROM Transactions;\", conn)\n",
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\3735338869.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customers = pd.read_sql(\"SELECT * FROM Customers;\", conn)\n",
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\3735338869.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  products = pd.read_sql(\"SELECT * FROM Products;\", conn)\n",
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\3735338869.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  stores = pd.read_sql(\"SELECT * FROM Stores;\", conn)\n",
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\3735338869.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  employees = pd.read_sql(\"SELECT * FROM Employees;\", conn)\n",
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\3735338869.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  discounts = pd.read_sql(\"SELECT * FROM Discounts;\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Example: load transactions table\n",
    "transactions = pd.read_sql(\"SELECT * FROM Transactions;\", conn)\n",
    "customers = pd.read_sql(\"SELECT * FROM Customers;\", conn)\n",
    "products = pd.read_sql(\"SELECT * FROM Products;\", conn)\n",
    "stores = pd.read_sql(\"SELECT * FROM Stores;\", conn)\n",
    "employees = pd.read_sql(\"SELECT * FROM Employees;\", conn)\n",
    "discounts = pd.read_sql(\"SELECT * FROM Discounts;\", conn)\n",
    "\n",
    "# Remove or comment out the next line:\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb99c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers: 1643306 rows, 9 cols\n",
      "Products: 14950 rows, 12 cols\n",
      "Employees: 403 rows, 4 cols\n",
      "Stores: 35 rows, 8 cols\n",
      "Discounts: 204 rows, 6 cols\n",
      "Transactions: 6284272 rows, 20 cols\n",
      "Duplicate Customers: 0\n",
      "Duplicate Products: 0\n",
      "Duplicate Employees: 0\n"
     ]
    }
   ],
   "source": [
    "# Row counts\n",
    "for name, df in [(\"Customers\", customers), (\"Products\", products),\n",
    "                 (\"Employees\", employees), (\"Stores\", stores),\n",
    "                 (\"Discounts\", discounts), (\"Transactions\", transactions)]:\n",
    "    print(f\"{name}: {df.shape[0]} rows, {df.shape[1]} cols\")\n",
    "\n",
    "# Duplicates check\n",
    "print(\"Duplicate Customers:\", customers[\"Customer_ID\"].duplicated().sum())\n",
    "print(\"Duplicate Products:\", products[\"Product_ID\"].duplicated().sum())\n",
    "print(\"Duplicate Employees:\", employees[\"Employee_ID\"].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b53686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the base tables to check\n",
    "tables = [\"Transactions\", \"Customers\", \"Products\", \"Stores\", \"Employees\", \"Discounts\"]\n",
    "\n",
    "# 3. Function: quick EDA summary\n",
    "def quick_summary(df, name):\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"Missing values:\\n\", df.isnull().sum())\n",
    "    print(\"Duplicate rows:\", df.duplicated().sum())\n",
    "    print(\"Data types:\\n\", df.dtypes)\n",
    "    print(\"-\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f9cdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\965312714.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {t};\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Transactions ---\n",
      "Shape: (6284272, 20)\n",
      "Missing values:\n",
      " Transaction_ID            0\n",
      "Invoice_ID                0\n",
      "Line                      0\n",
      "Customer_ID               0\n",
      "Product_ID                0\n",
      "Size                 405416\n",
      "Color               4259441\n",
      "Unit_Price                0\n",
      "Quantity                  0\n",
      "Date                      0\n",
      "Discount                  0\n",
      "Line_Total                0\n",
      "Store_ID                  0\n",
      "Employee_ID               0\n",
      "Currency                  0\n",
      "Currency_Symbol           0\n",
      "SKU                       0\n",
      "Transaction_Type          0\n",
      "Payment_Method            0\n",
      "Invoice_Total             0\n",
      "dtype: int64\n",
      "Duplicate rows: 0\n",
      "Data types:\n",
      " Transaction_ID               int64\n",
      "Invoice_ID                  object\n",
      "Line                         int64\n",
      "Customer_ID                  int64\n",
      "Product_ID                   int64\n",
      "Size                        object\n",
      "Color                       object\n",
      "Unit_Price                 float64\n",
      "Quantity                     int64\n",
      "Date                datetime64[ns]\n",
      "Discount                   float64\n",
      "Line_Total                 float64\n",
      "Store_ID                     int64\n",
      "Employee_ID                  int64\n",
      "Currency                    object\n",
      "Currency_Symbol             object\n",
      "SKU                         object\n",
      "Transaction_Type            object\n",
      "Payment_Method              object\n",
      "Invoice_Total              float64\n",
      "dtype: object\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\965312714.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {t};\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Customers ---\n",
      "Shape: (1643306, 9)\n",
      "Missing values:\n",
      " Customer_ID           0\n",
      "Name                  0\n",
      "Email                 0\n",
      "Telephone             0\n",
      "City                  0\n",
      "Country               0\n",
      "Gender                0\n",
      "Date_Of_Birth         0\n",
      "Job_Title        584153\n",
      "dtype: int64\n",
      "Duplicate rows: 0\n",
      "Data types:\n",
      " Customer_ID       int64\n",
      "Name             object\n",
      "Email            object\n",
      "Telephone        object\n",
      "City             object\n",
      "Country          object\n",
      "Gender           object\n",
      "Date_Of_Birth    object\n",
      "Job_Title        object\n",
      "dtype: object\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\965312714.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {t};\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Products ---\n",
      "Shape: (14950, 12)\n",
      "Missing values:\n",
      " Product_ID             0\n",
      "Category               0\n",
      "Sub_Category           0\n",
      "Description_PT         0\n",
      "Description_DE         0\n",
      "Description_FR         0\n",
      "Description_ES         0\n",
      "Description_EN         0\n",
      "Description_ZH         0\n",
      "Color              10382\n",
      "Sizes               1725\n",
      "Production_Cost        0\n",
      "dtype: int64\n",
      "Duplicate rows: 0\n",
      "Data types:\n",
      " Product_ID           int64\n",
      "Category            object\n",
      "Sub_Category        object\n",
      "Description_PT      object\n",
      "Description_DE      object\n",
      "Description_FR      object\n",
      "Description_ES      object\n",
      "Description_EN      object\n",
      "Description_ZH      object\n",
      "Color               object\n",
      "Sizes               object\n",
      "Production_Cost    float64\n",
      "dtype: object\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Stores ---\n",
      "Shape: (35, 8)\n",
      "Missing values:\n",
      " Store_ID               0\n",
      "Country                0\n",
      "City                   0\n",
      "Store_Name             0\n",
      "Number_of_Employees    0\n",
      "ZIP_Code               0\n",
      "Latitude               0\n",
      "Longitude              0\n",
      "dtype: int64\n",
      "Duplicate rows: 0\n",
      "Data types:\n",
      " Store_ID                 int64\n",
      "Country                 object\n",
      "City                    object\n",
      "Store_Name              object\n",
      "Number_of_Employees      int64\n",
      "ZIP_Code                object\n",
      "Latitude               float64\n",
      "Longitude              float64\n",
      "dtype: object\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Employees ---\n",
      "Shape: (403, 4)\n",
      "Missing values:\n",
      " Employee_ID    0\n",
      "Store_ID       0\n",
      "Name           0\n",
      "Position       0\n",
      "dtype: int64\n",
      "Duplicate rows: 0\n",
      "Data types:\n",
      " Employee_ID     int64\n",
      "Store_ID        int64\n",
      "Name           object\n",
      "Position       object\n",
      "dtype: object\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Discounts ---\n",
      "Shape: (204, 6)\n",
      "Missing values:\n",
      " Start            0\n",
      "End              0\n",
      "Discont          0\n",
      "Description      0\n",
      "Category        12\n",
      "Sub_Category    12\n",
      "dtype: int64\n",
      "Duplicate rows: 0\n",
      "Data types:\n",
      " Start            object\n",
      "End              object\n",
      "Discont         float64\n",
      "Description      object\n",
      "Category         object\n",
      "Sub_Category     object\n",
      "dtype: object\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\965312714.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {t};\", conn)\n",
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\965312714.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {t};\", conn)\n",
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_9596\\965312714.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {t};\", conn)\n"
     ]
    }
   ],
   "source": [
    "# 4. Load and check each table\n",
    "dataframes = {}\n",
    "for t in tables:\n",
    "    df = pd.read_sql(f\"SELECT * FROM {t};\", conn)\n",
    "    dataframes[t] = df\n",
    "    quick_summary(df, t)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09024411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with placeholders\n",
    "transactions[\"Size\"]  = transactions[\"Size\"].fillna(\"NA\")\n",
    "transactions[\"Color\"] = transactions[\"Color\"].fillna(\"Unknown\")\n",
    "\n",
    "products[\"Color\"] = products[\"Color\"].fillna(\"Unknown\")\n",
    "products[\"Sizes\"] = products[\"Sizes\"].fillna(\"Unknown\")\n",
    "\n",
    "discounts[\"Category\"]     = discounts[\"Category\"].fillna(\"Unknown\")\n",
    "discounts[\"Sub_Category\"] = discounts[\"Sub_Category\"].fillna(\"Unknown\")\n",
    "\n",
    "# Drop Job_Title if it's too sparse and not critical for analysis\n",
    "customers = customers.drop(columns=[\"Job_Title\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97611d8b",
   "metadata": {},
   "source": [
    "Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d4f66c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Transactions: 16605\n"
     ]
    }
   ],
   "source": [
    "# True duplicate check in transactions\n",
    "transaction_dupes = transactions.duplicated(\n",
    "    subset=[\"Invoice_ID\", \"Line\", \"Customer_ID\", \"Product_ID\"], keep=False\n",
    ")\n",
    "\n",
    "print(\"Duplicate Transactions:\", transaction_dupes.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e61eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.drop_duplicates(\n",
    "    subset=[\"Invoice_ID\", \"Line\", \"Customer_ID\", \"Product_ID\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4ad5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer duplicates: 0\n",
      "Product duplicates: 0\n",
      "Store duplicates: 0\n",
      "Employee duplicates: 0\n",
      "Discount duplicates: 0\n",
      "transactions duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Customer duplicates:\", customers[\"Customer_ID\"].duplicated().sum())\n",
    "print(\"Product duplicates:\", products[\"Product_ID\"].duplicated().sum())\n",
    "print(\"Store duplicates:\", stores[\"Store_ID\"].duplicated().sum())\n",
    "print(\"Employee duplicates:\", employees[\"Employee_ID\"].duplicated().sum())\n",
    "print(\"Discount duplicates:\", discounts.duplicated().sum())\n",
    "print(\"transactions duplicates:\", transactions.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d08ca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unit_Price      Quantity  Invoice_Total\n",
      "count  6.275861e+06  6.275861e+06   6.275861e+06\n",
      "mean   1.414065e+02  1.099750e+00   2.589320e+02\n",
      "std    1.914950e+02  3.953208e-01   5.551133e+02\n",
      "min    2.000000e+00  1.000000e+00  -6.453500e+03\n",
      "25%    3.300000e+01  1.000000e+00   3.488000e+01\n",
      "50%    5.300000e+01  1.000000e+00   8.800000e+01\n",
      "75%    1.650000e+02  1.000000e+00   2.605000e+02\n",
      "max    1.146000e+03  3.000000e+00   7.622500e+03\n",
      "High Unit Price outliers: 62678\n",
      "High Quantity outliers: 0\n",
      "High Invoice Total outliers: 62749\n"
     ]
    }
   ],
   "source": [
    "# Quick summary statistics\n",
    "print(transactions[[\"Unit_Price\", \"Quantity\", \"Invoice_Total\"]].describe())\n",
    "\n",
    "# Detect extreme outliers\n",
    "outliers_price = transactions[transactions[\"Unit_Price\"] > transactions[\"Unit_Price\"].quantile(0.99)]\n",
    "outliers_qty   = transactions[transactions[\"Quantity\"] > transactions[\"Quantity\"].quantile(0.99)]\n",
    "outliers_invoice = transactions[transactions[\"Invoice_Total\"] > transactions[\"Invoice_Total\"].quantile(0.99)]\n",
    "\n",
    "print(\"High Unit Price outliers:\", len(outliers_price))\n",
    "print(\"High Quantity outliers:\", len(outliers_qty))\n",
    "print(\"High Invoice Total outliers:\", len(outliers_invoice))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f0a6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(\n",
    "    \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "    \"Server=desktop-btvgd35\\\\SQLEXPRESS;\"\n",
    "    \"Database=global sales;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8338ad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting vwCategoryRevenue ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_16820\\827736438.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ vwCategoryRevenue exported successfully (3 rows).\n",
      "üì• Exporting vwCustomerOverview ...\n",
      "‚úÖ vwCustomerOverview exported successfully (1268571 rows).\n",
      "üì• Exporting vwCustomerSegments ...\n",
      "‚úÖ vwCustomerSegments exported successfully (1268571 rows).\n",
      "üì• Exporting vwCustomerValue ...\n",
      "‚úÖ vwCustomerValue exported successfully (1268571 rows).\n",
      "üì• Exporting vwDiscountEffectiveness ...\n",
      "‚úÖ vwDiscountEffectiveness exported successfully (70 rows).\n",
      "üì• Exporting vwDiscountImpact ...\n",
      "‚úÖ vwDiscountImpact exported successfully (3 rows).\n",
      "üì• Exporting vwPeakSalesDay ...\n",
      "‚úÖ vwPeakSalesDay exported successfully (1 rows).\n",
      "üì• Exporting vwRepeatCustomers ...\n",
      "‚úÖ vwRepeatCustomers exported successfully (1 rows).\n",
      "üì• Exporting vwRevenueByEmployee ...\n",
      "‚úÖ vwRevenueByEmployee exported successfully (263 rows).\n",
      "üì• Exporting vwRevenueByProduct ...\n",
      "‚úÖ vwRevenueByProduct exported successfully (14950 rows).\n",
      "üì• Exporting vwRevenueByStore ...\n",
      "‚úÖ vwRevenueByStore exported successfully (35 rows).\n",
      "üì• Exporting vwRevenueByYearMonth ...\n",
      "‚úÖ vwRevenueByYearMonth exported successfully (26 rows).\n",
      "üì• Exporting vwTop10Products ...\n",
      "‚úÖ vwTop10Products exported successfully (10 rows).\n",
      "üì• Exporting vwTopProducts ...\n",
      "‚úÖ vwTopProducts exported successfully (14950 rows).\n",
      "üì• Exporting vwReturnsSummary ...\n",
      "‚úÖ vwReturnsSummary exported successfully (1 rows).\n",
      "üì• Exporting vwReturnsByCategory ...\n",
      "‚úÖ vwReturnsByCategory exported successfully (3 rows).\n",
      "üì• Exporting vwReturnsByCountry ...\n",
      "‚úÖ vwReturnsByCountry exported successfully (7 rows).\n",
      "\n",
      "üéâ All exports completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# file: export_all_views.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ List all the views you want to export\n",
    "VIEWS = [\n",
    "    \"vwCategoryRevenue\",\n",
    "    \"vwCustomerOverview\",\n",
    "    \"vwCustomerSegments\",\n",
    "    \"vwCustomerValue\",\n",
    "    \"vwDiscountEffectiveness\",\n",
    "    \"vwDiscountImpact\",\n",
    "    \"vwPeakSalesDay\",\n",
    "    \"vwRepeatCustomers\",\n",
    "    \"vwRevenueByEmployee\",\n",
    "    \"vwRevenueByProduct\",\n",
    "    \"vwRevenueByStore\",\n",
    "    \"vwRevenueByYearMonth\",\n",
    "    \"vwTop10Products\",\n",
    "    \"vwTopProducts\",\n",
    "    \"vwReturnsSummary\",\n",
    "    \"vwReturnsByCategory\",\n",
    "    \"vwReturnsByCountry\",\n",
    "]\n",
    "\n",
    "# ‚úÖ Connect to your SQL Server\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Main export function\n",
    "def export_all_views_to_csv(output_folder: str):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        for view in VIEWS:\n",
    "            try:\n",
    "                print(f\"üì• Exporting {view} ...\")\n",
    "                query = f\"SELECT * FROM {view};\"\n",
    "                df = pd.read_sql(query, conn)\n",
    "\n",
    "                # Create full file path\n",
    "                file_path = os.path.join(output_folder, f\"{view}.csv\")\n",
    "                df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                print(f\"‚úÖ {view} exported successfully ({len(df)} rows).\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error exporting {view}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ‚ö†Ô∏è Update this path to your actual Desktop folder\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_views\")\n",
    "    export_all_views_to_csv(desktop_path)\n",
    "    print(\"\\nüéâ All exports completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8602c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting vwPaymentMethodRevenue ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_13756\\800858921.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ vwPaymentMethodRevenue exported successfully (2 rows).\n",
      "üì• Exporting vwPaymentMethodMonthlyTrend ...\n",
      "‚úÖ vwPaymentMethodMonthlyTrend exported successfully (52 rows).\n",
      "üì• Exporting vwPaymentMethodBySegment ...\n",
      "‚úÖ vwPaymentMethodBySegment exported successfully (1949498 rows).\n",
      "üì• Exporting vwPaymentShareSummary ...\n",
      "‚úÖ vwPaymentShareSummary exported successfully (2 rows).\n",
      "üì• Exporting vwPaymentNetMonthlyTrend ...\n",
      "‚úÖ vwPaymentNetMonthlyTrend exported successfully (52 rows).\n",
      "\n",
      "üéâ All exports completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# file: export_all_views.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ List all the views you want to export\n",
    "VIEWS = [\n",
    "    \"vwPaymentMethodRevenue\",\n",
    "    \"vwPaymentMethodMonthlyTrend\",\n",
    "    \"vwPaymentMethodBySegment\",\n",
    "    \"vwPaymentShareSummary\",\n",
    "    \"vwPaymentNetMonthlyTrend\",\n",
    "]\n",
    "\n",
    "# ‚úÖ Connect to your SQL Server\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Main export function\n",
    "def export_all_views_to_csv(output_folder: str):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        for view in VIEWS:\n",
    "            try:\n",
    "                print(f\"üì• Exporting {view} ...\")\n",
    "                query = f\"SELECT * FROM {view};\"\n",
    "                df = pd.read_sql(query, conn)\n",
    "\n",
    "                # Create full file path\n",
    "                file_path = os.path.join(output_folder, f\"{view}.csv\")\n",
    "                df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                print(f\"‚úÖ {view} exported successfully ({len(df)} rows).\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error exporting {view}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ‚ö†Ô∏è Update this path to your actual Desktop folder\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_views\")\n",
    "    export_all_views_to_csv(desktop_path)\n",
    "    print(\"\\nüéâ All exports completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313b2934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting vwPeakSalesDay ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_19000\\363538819.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ vwPeakSalesDay exported successfully (42 rows).\n",
      "\n",
      "üéâ All exports completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# file: export_all_views.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ List all the views you want to export\n",
    "VIEWS = [\n",
    "    \"vwPeakSalesDay\",  \n",
    "]\n",
    "\n",
    "# ‚úÖ Connect to your SQL Server\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Main export function\n",
    "def export_all_views_to_csv(output_folder: str):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        for view in VIEWS:\n",
    "            try:\n",
    "                print(f\"üì• Exporting {view} ...\")\n",
    "                query = f\"SELECT * FROM {view};\"\n",
    "                df = pd.read_sql(query, conn)\n",
    "\n",
    "                # Create full file path\n",
    "                file_path = os.path.join(output_folder, f\"{view}.csv\")\n",
    "                df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                print(f\"‚úÖ {view} exported successfully ({len(df)} rows).\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error exporting {view}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ‚ö†Ô∏è Update this path to your actual Desktop folder\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_views\")\n",
    "    export_all_views_to_csv(desktop_path)\n",
    "    print(\"\\nüéâ All exports completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7fd840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting vwCustomerStoreLink ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_22844\\139533787.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ vwCustomerStoreLink exported successfully (1268571 rows).\n",
      "\n",
      "üéâ All exports completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# file: export_all_views.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ List all the views you want to export\n",
    "VIEWS = [\n",
    "    \"vwCustomerStoreLink\",  \n",
    "]\n",
    "\n",
    "# ‚úÖ Connect to your SQL Server\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Main export function\n",
    "def export_all_views_to_csv(output_folder: str):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        for view in VIEWS:\n",
    "            try:\n",
    "                print(f\"üì• Exporting {view} ...\")\n",
    "                query = f\"SELECT * FROM {view};\"\n",
    "                df = pd.read_sql(query, conn)\n",
    "\n",
    "                # Create full file path\n",
    "                file_path = os.path.join(output_folder, f\"{view}.csv\")\n",
    "                df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                print(f\"‚úÖ {view} exported successfully ({len(df)} rows).\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error exporting {view}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ‚ö†Ô∏è Update this path to your actual Desktop folder\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_views\")\n",
    "    export_all_views_to_csv(desktop_path)\n",
    "    print(\"\\nüéâ All exports completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470a7a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting vwCustomerStoreProfile ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_18160\\757757835.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ vwCustomerStoreProfile exported successfully (1615280 rows).\n",
      "üì• Exporting vwStoreCustomerSummary ...\n",
      "‚ùå Error exporting vwStoreCustomerSummary: Execution failed on sql 'SELECT * FROM vwStoreCustomerSummary;': ('42S02', \"[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Invalid object name 'vwStoreCustomerSummary'. (208) (SQLExecDirectW)\")\n",
      "\n",
      "üéâ All exports completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# file: export_all_views.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ List all the views you want to export\n",
    "VIEWS = [  \n",
    "     \"vwCustomerStoreProfile\",\n",
    "    \"vwStoreCustomerSummary\"\n",
    "]\n",
    "\n",
    "# ‚úÖ Connect to your SQL Server\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Main export function\n",
    "def export_all_views_to_csv(output_folder: str):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        for view in VIEWS:\n",
    "            try:\n",
    "                print(f\"üì• Exporting {view} ...\")\n",
    "                query = f\"SELECT * FROM {view};\"\n",
    "                df = pd.read_sql(query, conn)\n",
    "\n",
    "                # Create full file path\n",
    "                file_path = os.path.join(output_folder, f\"{view}.csv\")\n",
    "                df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                print(f\"‚úÖ {view} exported successfully ({len(df)} rows).\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error exporting {view}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ‚ö†Ô∏è Update this path to your actual Desktop folder\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_views\")\n",
    "    export_all_views_to_csv(desktop_path)\n",
    "    print(\"\\nüéâ All exports completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57115c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting vwCustomerNearestStore ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_18160\\376302714.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ vwCustomerNearestStore exported successfully (1268571 rows).\n",
      "üì• Exporting vwPeakSalesHour ...\n",
      "‚úÖ vwPeakSalesHour exported successfully (546 rows).\n",
      "üì• Exporting vwCustomerNearestStore ...\n",
      "‚úÖ vwCustomerNearestStore exported successfully (1268571 rows).\n",
      "\n",
      "üéâ All exports completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# file: export_all_views.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ List all the views you want to export\n",
    "VIEWS = [  \n",
    "     \"vwCustomerNearestStore\",\n",
    "    \"vwPeakSalesHour\",\n",
    "     \"vwCustomerNearestStore\",\n",
    "]\n",
    "\n",
    "# ‚úÖ Connect to your SQL Server\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Main export function\n",
    "def export_all_views_to_csv(output_folder: str):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        for view in VIEWS:\n",
    "            try:\n",
    "                print(f\"üì• Exporting {view} ...\")\n",
    "                query = f\"SELECT * FROM {view};\"\n",
    "                df = pd.read_sql(query, conn)\n",
    "\n",
    "                # Create full file path\n",
    "                file_path = os.path.join(output_folder, f\"{view}.csv\")\n",
    "                df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                print(f\"‚úÖ {view} exported successfully ({len(df)} rows).\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error exporting {view}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ‚ö†Ô∏è Update this path to your actual Desktop folder\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_views\")\n",
    "    export_all_views_to_csv(desktop_path)\n",
    "    print(\"\\nüéâ All exports completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca382bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"vwCustomerNearestStore\"\n",
    "\"vwPeakSalesHour\"\n",
    "\"vwCustomerNearestStore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59196752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting vwDiscountEffectiveness ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_21096\\3277918921.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ vwDiscountEffectiveness exported successfully (70 rows).\n",
      "üì• Exporting vwDiscountImpact ...\n",
      "‚úÖ vwDiscountImpact exported successfully (3 rows).\n",
      "\n",
      "üéâ All exports completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# file: export_all_views.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ List all the views you want to export\n",
    "VIEWS = [  \n",
    "    \"vwDiscountEffectiveness\",\n",
    "     \"vwDiscountImpact\",\n",
    "]\n",
    "\n",
    "# ‚úÖ Connect to your SQL Server\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Main export function\n",
    "def export_all_views_to_csv(output_folder: str):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        for view in VIEWS:\n",
    "            try:\n",
    "                print(f\"üì• Exporting {view} ...\")\n",
    "                query = f\"SELECT * FROM {view};\"\n",
    "                df = pd.read_sql(query, conn)\n",
    "\n",
    "                # Create full file path\n",
    "                file_path = os.path.join(output_folder, f\"{view}.csv\")\n",
    "                df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                print(f\"‚úÖ {view} exported successfully ({len(df)} rows).\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error exporting {view}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ‚ö†Ô∏è Update this path to your actual Desktop folder\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_views\")\n",
    "    export_all_views_to_csv(desktop_path)\n",
    "    print(\"\\nüéâ All exports completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37551206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting vwCustomerStoreProfile ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_8704\\3098599877.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ vwCustomerStoreProfile exported successfully (1615280 rows).\n",
      "\n",
      "üéâ All exports completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# file: export_all_views.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ List all the views you want to export\n",
    "VIEWS = [  \n",
    "     \"vwCustomerOverview\",\n",
    "]\n",
    "\n",
    "# ‚úÖ Connect to your SQL Server\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Main export function\n",
    "def export_all_views_to_csv(output_folder: str):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        for view in VIEWS:\n",
    "            try:\n",
    "                print(f\"üì• Exporting {view} ...\")\n",
    "                query = f\"SELECT * FROM {view};\"\n",
    "                df = pd.read_sql(query, conn)\n",
    "\n",
    "                # Create full file path\n",
    "                file_path = os.path.join(output_folder, f\"{view}.csv\")\n",
    "                df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                print(f\"‚úÖ {view} exported successfully ({len(df)} rows).\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error exporting {view}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ‚ö†Ô∏è Update this path to your actual Desktop folder\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_views\")\n",
    "    export_all_views_to_csv(desktop_path)\n",
    "    print(\"\\nüéâ All exports completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d773778a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting table: transactions in chunks of 500,000 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_16488\\4166415109.py:28: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  chunk_iter = pd.read_sql(f\"SELECT * FROM {TABLE_NAME};\", conn, chunksize=chunksize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 1 exported (500,000 rows, total 500,000)\n",
      "‚úÖ Chunk 2 exported (500,000 rows, total 1,000,000)\n",
      "‚úÖ Chunk 3 exported (500,000 rows, total 1,500,000)\n",
      "‚úÖ Chunk 4 exported (500,000 rows, total 2,000,000)\n",
      "‚úÖ Chunk 5 exported (500,000 rows, total 2,500,000)\n",
      "‚úÖ Chunk 6 exported (500,000 rows, total 3,000,000)\n",
      "‚úÖ Chunk 7 exported (500,000 rows, total 3,500,000)\n",
      "‚úÖ Chunk 8 exported (500,000 rows, total 4,000,000)\n",
      "‚úÖ Chunk 9 exported (500,000 rows, total 4,500,000)\n",
      "‚úÖ Chunk 10 exported (500,000 rows, total 5,000,000)\n",
      "‚úÖ Chunk 11 exported (500,000 rows, total 5,500,000)\n",
      "‚úÖ Chunk 12 exported (500,000 rows, total 6,000,000)\n",
      "‚úÖ Chunk 13 exported (284,272 rows, total 6,284,272)\n",
      "\n",
      "üéâ Export completed successfully! (6,284,272 total rows)\n",
      "üìÇ Saved to: C:\\Users\\Antifragile/Desktop/global_sales_exports\\transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# file: export_transactions.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ Table name to export\n",
    "TABLE_NAME = \"transactions\"\n",
    "\n",
    "# ‚úÖ Create SQL Server connection\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Export large table in chunks to avoid RAM overload\n",
    "def export_table_to_csv(output_folder: str, chunksize: int = 500_000):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    file_path = os.path.join(output_folder, f\"{TABLE_NAME}.csv\")\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        try:\n",
    "            print(f\"üì• Exporting table: {TABLE_NAME} in chunks of {chunksize:,} rows...\")\n",
    "\n",
    "            # Read in chunks to manage large data efficiently\n",
    "            chunk_iter = pd.read_sql(f\"SELECT * FROM {TABLE_NAME};\", conn, chunksize=chunksize)\n",
    "            \n",
    "            first = True\n",
    "            total_rows = 0\n",
    "            for i, chunk in enumerate(chunk_iter):\n",
    "                chunk.to_csv(file_path, index=False, mode=\"w\" if first else \"a\", \n",
    "                             header=first, encoding=\"utf-8-sig\")\n",
    "                first = False\n",
    "                total_rows += len(chunk)\n",
    "                print(f\"‚úÖ Chunk {i+1} exported ({len(chunk):,} rows, total {total_rows:,})\")\n",
    "\n",
    "            print(f\"\\nüéâ Export completed successfully! ({total_rows:,} total rows)\")\n",
    "            print(f\"üìÇ Saved to: {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error exporting {TABLE_NAME}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_exports\")\n",
    "    export_table_to_csv(desktop_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c41263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Exporting table: stores in chunks of 500,000 rows...\n",
      "‚úÖ Chunk 1 exported (35 rows, total 35)\n",
      "\n",
      "üéâ Export completed successfully! (35 total rows)\n",
      "üìÇ Saved to: C:\\Users\\Antifragile/Desktop/global_sales_exports\\stores.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_16488\\1838380765.py:28: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  chunk_iter = pd.read_sql(f\"SELECT * FROM {TABLE_NAME};\", conn, chunksize=chunksize)\n"
     ]
    }
   ],
   "source": [
    "# file: export_transactions.py\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# ‚úÖ Table name to export\n",
    "TABLE_NAME = \"stores\" \n",
    "\n",
    "# ‚úÖ Create SQL Server connection\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "# ‚úÖ Export large table in chunks to avoid RAM overload\n",
    "def export_table_to_csv(output_folder: str, chunksize: int = 500_000):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    file_path = os.path.join(output_folder, f\"{TABLE_NAME}.csv\")\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        try:\n",
    "            print(f\"üì• Exporting table: {TABLE_NAME} in chunks of {chunksize:,} rows...\")\n",
    "\n",
    "            # Read in chunks to manage large data efficiently\n",
    "            chunk_iter = pd.read_sql(f\"SELECT * FROM {TABLE_NAME};\", conn, chunksize=chunksize)\n",
    "            \n",
    "            first = True\n",
    "            total_rows = 0\n",
    "            for i, chunk in enumerate(chunk_iter):\n",
    "                chunk.to_csv(file_path, index=False, mode=\"w\" if first else \"a\", \n",
    "                             header=first, encoding=\"utf-8-sig\")\n",
    "                first = False\n",
    "                total_rows += len(chunk)\n",
    "                print(f\"‚úÖ Chunk {i+1} exported ({len(chunk):,} rows, total {total_rows:,})\")\n",
    "\n",
    "            print(f\"\\nüéâ Export completed successfully! ({total_rows:,} total rows)\")\n",
    "            print(f\"üìÇ Saved to: {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error exporting {TABLE_NAME}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    desktop_path = os.path.expanduser(\"~/Desktop/global_sales_exports\")\n",
    "    export_table_to_csv(desktop_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee969658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Exporting transactions in chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_10760\\3212533517.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  chunk_iter = pd.read_sql(query, conn, chunksize=chunk_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 1: 500000 rows\n",
      "‚úÖ Chunk 2: 500000 rows\n",
      "‚úÖ Chunk 3: 500000 rows\n",
      "‚úÖ Chunk 4: 500000 rows\n",
      "‚úÖ Chunk 5: 500000 rows\n",
      "‚úÖ Chunk 6: 500000 rows\n",
      "‚úÖ Chunk 7: 500000 rows\n",
      "‚úÖ Chunk 8: 500000 rows\n",
      "‚úÖ Chunk 9: 500000 rows\n",
      "‚úÖ Chunk 10: 500000 rows\n",
      "‚úÖ Chunk 11: 500000 rows\n",
      "‚úÖ Chunk 12: 500000 rows\n",
      "‚úÖ Chunk 13: 284272 rows\n",
      "üéâ Export completed! Saved to C:\\Users\\Antifragile/Desktop/global_sales_exports\\transactions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "TABLE_NAME = \"transactions\"\n",
    "\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "def export_large_table_in_chunks(output_folder: str, chunk_size: int = 500_000):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    file_path = os.path.join(output_folder, f\"{TABLE_NAME}.csv\")\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        query = f\"SELECT * FROM {TABLE_NAME}\"\n",
    "        print(f\"üì¶ Exporting {TABLE_NAME} in chunks...\")\n",
    "\n",
    "        chunk_iter = pd.read_sql(query, conn, chunksize=chunk_size)\n",
    "        first = True\n",
    "        for i, chunk in enumerate(chunk_iter, 1):\n",
    "            mode = \"w\" if first else \"a\"\n",
    "            header = first\n",
    "            chunk.to_csv(file_path, mode=mode, header=header, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úÖ Chunk {i}: {len(chunk)} rows\")\n",
    "            first = False\n",
    "\n",
    "        print(f\"üéâ Export completed! Saved to {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    export_large_table_in_chunks(os.path.expanduser(\"~/Desktop/global_sales_exports\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5699947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Exporting customers in chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antifragile\\AppData\\Local\\Temp\\ipykernel_14760\\3236647696.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  chunk_iter = pd.read_sql(query, conn, chunksize=chunk_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 1: 500000 rows\n",
      "‚úÖ Chunk 2: 500000 rows\n",
      "‚úÖ Chunk 3: 500000 rows\n",
      "‚úÖ Chunk 4: 143306 rows\n",
      "üéâ Export completed! Saved to C:\\Users\\Antifragile/Desktop/global_sales_exports\\customers.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "TABLE_NAME = \"customers\"\n",
    "\n",
    "def get_connection():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=DESKTOP-BTVGD35\\\\SQLEXPRESS;\"\n",
    "        \"DATABASE=global sales;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "def export_large_table_in_chunks(output_folder: str, chunk_size: int = 500_000):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    file_path = os.path.join(output_folder, f\"{TABLE_NAME}.csv\")\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        query = f\"SELECT * FROM {TABLE_NAME}\"\n",
    "        print(f\"üì¶ Exporting {TABLE_NAME} in chunks...\")\n",
    "\n",
    "        chunk_iter = pd.read_sql(query, conn, chunksize=chunk_size)\n",
    "        first = True\n",
    "        for i, chunk in enumerate(chunk_iter, 1):\n",
    "            mode = \"w\" if first else \"a\"\n",
    "            header = first\n",
    "            chunk.to_csv(file_path, mode=mode, header=header, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úÖ Chunk {i}: {len(chunk)} rows\")\n",
    "            first = False\n",
    "\n",
    "        print(f\"üéâ Export completed! Saved to {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    export_large_table_in_chunks(os.path.expanduser(\"~/Desktop/global_sales_exports\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec200b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"Set2\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ All CSVs loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# List all uploaded files in Colab's current directory (/content)\n",
    "files = [f for f in os.listdir('/content') if f.endswith('.csv')]\n",
    "\n",
    "# Dictionary to hold all dataframes\n",
    "dataframes = {}\n",
    "\n",
    "for file in files:\n",
    "    name = os.path.splitext(file)[0]  # strip .csv\n",
    "    df = pd.read_csv(f'/content/{file}', encoding='utf-8-sig')\n",
    "    dataframes[name] = df\n",
    "    print(f\"‚úÖ Loaded {name} ({len(df)} rows)\")\n",
    "\n",
    "# Create a copy of dataframes and assign it to dfs\n",
    "dfs = dataframes.copy()\n",
    "\n",
    "print(\"\\nüéâ All CSVs loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vwCategoryGrossRevenue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-843941203.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Aggregate key metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgross_revenue\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vwCategoryGrossRevenue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GrossRevenue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mreturns_value\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vwCategoryReturns\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ReturnValue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnet_revenue\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vwCategoryRevenue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TotalRevenue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Note: column is 'TotalRevenue'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vwCategoryGrossRevenue'"
     ]
    }
   ],
   "source": [
    "# --- Executive Revenue Overview ---\n",
    "\n",
    "# Aggregate key metrics\n",
    "gross_revenue   = dfs[\"vwCategoryGrossRevenue\"][\"GrossRevenue\"].sum()\n",
    "returns_value   = dfs[\"vwCategoryReturns\"][\"ReturnValue\"].sum()\n",
    "net_revenue     = dfs[\"vwCategoryRevenue\"][\"TotalRevenue\"].sum()  # Note: column is 'TotalRevenue'\n",
    "\n",
    "# Compute ratios\n",
    "return_ratio = abs(returns_value / gross_revenue) * 100\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüìà EXECUTIVE REVENUE OVERVIEW\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Gross Revenue:   ${gross_revenue:,.2f}\")\n",
    "print(f\"Returns (Loss):  ${returns_value:,.2f}\")\n",
    "print(f\"Net Revenue:     ${net_revenue:,.2f}\")\n",
    "print(f\"Return Ratio:    {return_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: missing views in dfs: ['vwCategoryGrossRevenue', 'vwCategoryReturns', 'vwCategoryRevenue']\n",
      "\n",
      "üìà EXECUTIVE REVENUE OVERVIEW\n",
      "----------------------------------------\n",
      "Gross Revenue:   $0.00\n",
      "Returns (Loss):  $0.00\n",
      "Net Revenue:     $0.00\n",
      "Return Ratio:    N/A (gross revenue missing or zero)\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# safe executive overview (handles missing view keys)\n",
    "required = {\n",
    "    \"gross\": \"vwCategoryGrossRevenue\",\n",
    "    \"returns\": \"vwCategoryReturns\",\n",
    "    \"net\": \"vwCategoryRevenue\"\n",
    "}\n",
    "\n",
    "# try to load missing views from CSV files in current folder (if available)\n",
    "missing = [v for v in required.values() if v not in dfs]\n",
    "if missing:\n",
    "    print(\"WARNING: missing views in dfs:\", missing)\n",
    "    for v in missing:\n",
    "        csv_path = os.path.join(os.getcwd(), f\"{v}.csv\")\n",
    "        if os.path.exists(csv_path):\n",
    "            try:\n",
    "                dfs[v] = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "                print(f\"Loaded {csv_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {csv_path}: {e}\")\n",
    "\n",
    "# aggregate safely (use .get to avoid KeyError)\n",
    "gross_revenue = dfs.get(required[\"gross\"], pd.DataFrame()).get(\"GrossRevenue\", pd.Series(dtype=float)).sum()\n",
    "returns_value = dfs.get(required[\"returns\"], pd.DataFrame()).get(\"ReturnValue\", pd.Series(dtype=float)).sum()\n",
    "net_revenue = dfs.get(required[\"net\"], pd.DataFrame()).get(\"TotalRevenue\", pd.Series(dtype=float)).sum()\n",
    "\n",
    "# avoid division by zero\n",
    "if gross_revenue and gross_revenue != 0:\n",
    "    return_ratio = abs(returns_value / gross_revenue) * 100\n",
    "else:\n",
    "    return_ratio = np.nan\n",
    "\n",
    "# display results\n",
    "print(\"\\nüìà EXECUTIVE REVENUE OVERVIEW\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Gross Revenue:   ${gross_revenue:,.2f}\")\n",
    "print(f\"Returns (Loss):  ${returns_value:,.2f}\")\n",
    "print(f\"Net Revenue:     ${net_revenue:,.2f}\")\n",
    "if not np.isnan(return_ratio):\n",
    "    print(f\"Return Ratio:    {return_ratio:.2f}%\")\n",
    "else:\n",
    "    print(\"Return Ratio:    N/A (gross revenue missing or zero)\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
