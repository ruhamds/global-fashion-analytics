{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#load tables\n",
        "customers = pd.read_csv(\"customers.csv\")\n",
        "products = pd.read_csv(\"products.csv\")\n",
        "stores = pd.read_csv(\"stores.csv\")\n",
        "employees = pd.read_csv(\"employees.csv\")\n",
        "discounts = pd.read_csv(\"discounts.csv\")\n",
        "transactions = pd.read_csv(\"transactions.csv\")"
      ],
      "metadata": {
        "id": "QwpUtk7intwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d421a948",
        "outputId": "8e22b31b-6844-48f6-b0b7-c3b64b7a0546"
      },
      "source": [
        "transactions.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 663870 entries, 0 to 663869\n",
            "Data columns (total 20 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   Transaction_ID    663870 non-null  int64  \n",
            " 1   Invoice_ID        663870 non-null  object \n",
            " 2   Line              663870 non-null  int64  \n",
            " 3   Customer_ID       663870 non-null  int64  \n",
            " 4   Product_ID        663870 non-null  int64  \n",
            " 5   Size              621115 non-null  object \n",
            " 6   Color             217232 non-null  object \n",
            " 7   Unit_Price        663870 non-null  float64\n",
            " 8   Quantity          663870 non-null  int64  \n",
            " 9   Date              663870 non-null  object \n",
            " 10  Discount          663870 non-null  float64\n",
            " 11  Line_Total        663870 non-null  float64\n",
            " 12  Store_ID          663870 non-null  int64  \n",
            " 13  Employee_ID       663870 non-null  int64  \n",
            " 14  Currency          663870 non-null  object \n",
            " 15  Currency_Symbol   663870 non-null  object \n",
            " 16  SKU               663870 non-null  object \n",
            " 17  Transaction_Type  663870 non-null  object \n",
            " 18  Payment_Method    663870 non-null  object \n",
            " 19  Invoice_Total     663870 non-null  float64\n",
            "dtypes: float64(4), int64(7), object(9)\n",
            "memory usage: 101.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BASIC SHAPE CHECKS\n",
        "print(f\"Transactions: {transactions.shape}, Customers: {customers.shape}, Products: {products.shape}, Stores: {stores.shape}\")\n",
        "\n",
        "# NULL CHECKS\n",
        "for name, df in [('Transactions', transactions), ('Customers', customers),\n",
        "                 ('Products', products), ('Stores', stores)]:\n",
        "    missing = df.isna().sum().sum()\n",
        "    print(f\"{name}: {missing} missing values total\")\n",
        "\n",
        "# DUPLICATE CHECKS\n",
        "print(f\"Duplicate Transactions: {transactions.duplicated().sum()}\")\n",
        "\n",
        "# KEY COLUMN VALIDATION\n",
        "print(\"üîë Key Column Integrity Check\")\n",
        "missing_customers = transactions[~transactions['Customer_ID'].isin(customers['Customer_ID'])]\n",
        "missing_products = transactions[~transactions['Product_ID'].isin(products['Product_ID'])]\n",
        "print(f\"Missing Customer IDs in transactions: {len(missing_customers)}\")\n",
        "print(f\"Missing Product IDs in transactions: {len(missing_products)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwAVi_Cs5WRY",
        "outputId": "e4aaf881-b3b1-4844-bca7-29195832de15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transactions: (6284272, 20), Customers: (1643306, 9), Products: (14950, 13), Stores: (35, 8)\n",
            "Transactions: 4664857 missing values total\n",
            "Customers: 584153 missing values total\n",
            "Products: 12107 missing values total\n",
            "Stores: 0 missing values total\n",
            "Duplicate Transactions: 0\n",
            "üîë Key Column Integrity Check\n",
            "Missing Customer IDs in transactions: 0\n",
            "Missing Product IDs in transactions: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Row counts\n",
        "for name, df in [(\"Customers\", customers), (\"Products\", products),\n",
        "                 (\"Employees\", employees), (\"Stores\", stores),\n",
        "                 (\"Discounts\", discounts), (\"Transactions\", transactions)]:\n",
        "    print(f\"{name}: {df.shape[0]} rows, {df.shape[1]} cols\")\n",
        "\n",
        "# Duplicates check\n",
        "print(\"Duplicate Customers:\", customers[\"Customer_ID\"].duplicated().sum())\n",
        "print(\"Duplicate Products:\", products[\"Product_ID\"].duplicated().sum())\n",
        "print(\"Duplicate Employees:\", employees[\"Employee_ID\"].duplicated().sum())"
      ],
      "metadata": {
        "id": "H8OzEj1Asklu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b270a0e-18ea-430f-d40a-b7de8e3d3e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers: 1643306 rows, 9 cols\n",
            "Products: 14950 rows, 13 cols\n",
            "Employees: 403 rows, 4 cols\n",
            "Stores: 35 rows, 8 cols\n",
            "Discounts: 204 rows, 6 cols\n",
            "Transactions: 6284272 rows, 20 cols\n",
            "Duplicate Customers: 0\n",
            "Duplicate Products: 0\n",
            "Duplicate Employees: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Verify foreign key integrity before joins\n",
        "\n",
        "# transactions, customers, products, stores, employees, discounts\n",
        "\n",
        "# Define expected foreign key relationships\n",
        "fk_checks = {\n",
        "    \"Customer_ID\": customers[\"Customer_ID\"],\n",
        "    \"Product_ID\": products[\"Product_ID\"],\n",
        "    \"Store_ID\": stores[\"Store_ID\"],\n",
        "    \"Employee_ID\": employees[\"Employee_ID\"],\n",
        "    # \"Discount_ID\": discounts[\"Discount_ID\"], # Removed as Discount_ID column does not exist\n",
        "}\n",
        "\n",
        "for col, valid_ids in fk_checks.items():\n",
        "    if col in transactions.columns:\n",
        "        missing = ~transactions[col].isin(valid_ids)\n",
        "        missing_count = missing.sum()\n",
        "        total = len(transactions)\n",
        "        print(f\"{col}: {missing_count} missing ({(missing_count/total)*100:.2f}%)\")\n",
        "        if missing_count > 0:\n",
        "            print(f\"‚ö†Ô∏è  Example missing IDs: {transactions.loc[missing, col].unique()[:5]}\")\n",
        "    else:\n",
        "        print(f\"{col}: not found in Transactions table.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE-HK2BIa4ql",
        "outputId": "d88953ae-1811-4a99-9479-d23c5e0e4e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer_ID: 0 missing (0.00%)\n",
            "Product_ID: 0 missing (0.00%)\n",
            "Store_ID: 0 missing (0.00%)\n",
            "Employee_ID: 0 missing (0.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a mapping: column in transactions -> valid IDs series in lookup table\n",
        "fk_checks = {\n",
        "    \"Customer_ID\": customers[\"Customer_ID\"] if \"Customer_ID\" in customers.columns else None,\n",
        "    \"Product_ID\": products[\"Product_ID\"] if \"Product_ID\" in products.columns else None,\n",
        "    \"Store_ID\": stores[\"Store_ID\"] if \"Store_ID\" in stores.columns else None,\n",
        "    \"Employee_ID\": employees[\"Employee_ID\"] if \"Employee_ID\" in employees.columns else None,\n",
        "    # Do not include Discount_ID if it doesn't exist\n",
        "}\n",
        "\n",
        "print(\"üîé Running FK checks (only for keys that exist in both sides)...\\n\")\n",
        "for tx_col, valid_ids in fk_checks.items():\n",
        "    if tx_col not in transactions.columns:\n",
        "        print(f\"‚Ä¢ {tx_col}: not present in transactions ‚Üí skipping\")\n",
        "        continue\n",
        "    if valid_ids is None:\n",
        "        print(f\"‚Ä¢ {tx_col}: lookup table missing column ‚Üí skipping\")\n",
        "        continue\n",
        "\n",
        "    missing_mask = ~transactions[tx_col].isin(valid_ids)\n",
        "    missing_count = int(missing_mask.sum())\n",
        "    total = len(transactions)\n",
        "    print(f\"‚Ä¢ {tx_col}: {missing_count:,} missing ({missing_count/total*100:.4f}%)\")\n",
        "    if missing_count:\n",
        "        print(f\"   Example missing values (up to 10): {transactions.loc[missing_mask, tx_col].unique()[:10]}\")\n",
        "        # optionally save a sample for inspection\n",
        "        sample = transactions.loc[missing_mask].head(5)\n",
        "        display(sample)\n",
        "\n",
        "# ----------------------------\n",
        "# Discount-specific checks\n",
        "# ----------------------------\n",
        "print(\"\\nüîé Discount-related checks\")\n",
        "\n",
        "# 1) Is there an explicit Discount_ID link in either table?\n",
        "if \"Discount_ID\" in transactions.columns and \"Discount_ID\" in discounts.columns:\n",
        "    missing_mask = ~transactions[\"Discount_ID\"].isin(discounts[\"Discount_ID\"])\n",
        "    print(f\"‚Ä¢ Discount_ID FK missing: {missing_mask.sum():,} rows\")\n",
        "else:\n",
        "    print(\"‚Ä¢ No Discount_ID FK available in both tables. Checking alternative discount columns...\")\n",
        "\n",
        "# 2) If transactions have DiscountCode or DiscountName or DiscountPercent, inspect those\n",
        "alt_discount_cols = [c for c in (\"DiscountCode\", \"Discount_Name\", \"DiscountPercent\", \"Discount\") if c in transactions.columns]\n",
        "if alt_discount_cols:\n",
        "    print(f\"‚Ä¢ Found discount-like columns in transactions: {alt_discount_cols}\")\n",
        "    # Quick checks: % of transactions with non-null discount info; distribution of DiscountPercent\n",
        "    if \"DiscountPercent\" in transactions.columns:\n",
        "        non_null = transactions[\"DiscountPercent\"].notna().sum()\n",
        "        print(f\"  - DiscountPercent present for {non_null:,} / {len(transactions):,} transactions ({non_null/len(transactions):.2%})\")\n",
        "        print(\"  - DiscountPercent summary:\")\n",
        "        display(transactions[\"DiscountPercent\"].describe().to_frame().T)\n",
        "    # If there's a discounts table with codes, compare unique codes\n",
        "    if \"DiscountCode\" in transactions.columns and \"Code\" in discounts.columns:\n",
        "        tx_codes = set(transactions[\"DiscountCode\"].dropna().unique())\n",
        "        lookup_codes = set(discounts[\"Code\"].dropna().unique())\n",
        "        missing_codes = sorted(list(tx_codes - lookup_codes))[:10]\n",
        "        print(f\"  - Discount codes in transactions not found in discounts table: {len(tx_codes - lookup_codes)} (example: {missing_codes})\")\n",
        "else:\n",
        "    print(\"‚Ä¢ No discount-related columns found in transactions to check.\")\n",
        "\n",
        "# ----------------------------\n",
        "# Optionally save orphan rows for offline inspection\n",
        "# ----------------------------\n",
        "save_orphans = False  # set True to save example orphan rows\n",
        "if save_orphans:\n",
        "    orphan_dir = \"orphan_samples\"\n",
        "    import os\n",
        "    os.makedirs(orphan_dir, exist_ok=True)\n",
        "    for tx_col, valid_ids in fk_checks.items():\n",
        "        if tx_col in transactions.columns and valid_ids is not None:\n",
        "            missing_mask = ~transactions[tx_col].isin(valid_ids)\n",
        "            if missing_mask.any():\n",
        "                fname = f\"{orphan_dir}/orphans_{tx_col}.csv\"\n",
        "                transactions.loc[missing_mask].head(100).to_csv(fname, index=False)\n",
        "                print(f\"Saved sample orphans for {tx_col} -> {fname}\")\n",
        "\n",
        "print(\"\\n‚úÖ FK checks complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB8oNcr_cH49",
        "outputId": "93a65f07-7dee-48c1-91b2-fbf08da4a628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîé Running FK checks (only for keys that exist in both sides)...\n",
            "\n",
            "‚Ä¢ Customer_ID: 0 missing (0.0000%)\n",
            "‚Ä¢ Product_ID: 0 missing (0.0000%)\n",
            "‚Ä¢ Store_ID: 0 missing (0.0000%)\n",
            "‚Ä¢ Employee_ID: 0 missing (0.0000%)\n",
            "\n",
            "üîé Discount-related checks\n",
            "‚Ä¢ No Discount_ID FK available in both tables. Checking alternative discount columns...\n",
            "‚Ä¢ Found discount-like columns in transactions: ['Discount']\n",
            "\n",
            "‚úÖ FK checks complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_date = pd.Timestamp.today().normalize()\n",
        "\n",
        "transactions[\"Date\"] = pd.to_datetime(transactions[\"Date\"], errors=\"coerce\")\n",
        "print(\"üìÖ Dataset time window:\")\n",
        "print(f\"   Start: {transactions['Date'].min().date()}\")\n",
        "print(f\"   End:   {transactions['Date'].max().date()}\")\n",
        "print(f\"   Current date reference for churn: {current_date.date()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqw4e8HDzlio",
        "outputId": "49a93a28-6bd2-4e3e-c22e-e69b10b8c303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Dataset time window:\n",
            "   Start: 2023-01-01\n",
            "   End:   2025-02-22\n",
            "   Current date reference for churn: 2025-11-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# üåü FULL FEATURE ENGINEERING PIPELINE (CHURN-FIXED)\n",
        "# ================================================================\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------------------\n",
        "# 0Ô∏è‚É£ Helper: Optimize DataFrame\n",
        "# ------------------------------\n",
        "def optimize_df(df, name=\"df\"):\n",
        "    print(f\"\\nOptimizing {name}...\")\n",
        "    original_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "\n",
        "    # Convert object columns to category first\n",
        "    for col in df.select_dtypes(include=\"object\").columns:\n",
        "        df[col] = df[col].astype(\"category\")\n",
        "\n",
        "    # Use convert_dtypes for the rest\n",
        "    df = df.convert_dtypes()\n",
        "    final_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    print(f\"‚úÖ Optimized {name}: {df.shape[0]:,} rows, {final_mem:.2f} MB (from {original_mem:.2f} MB)\")\n",
        "    return df\n",
        "\n",
        "# ------------------------------\n",
        "# 1Ô∏è‚É£ Optimize base tables\n",
        "# ------------------------------\n",
        "transactions = optimize_df(transactions, \"transactions\")\n",
        "customers = optimize_df(customers, \"customers\")\n",
        "products = optimize_df(products, \"products\")\n",
        "stores = optimize_df(stores, \"stores\")\n",
        "\n",
        "# ------------------------------\n",
        "# 2Ô∏è‚É£ Set reference date for churn\n",
        "# ------------------------------\n",
        "# Use dataset max date + small buffer to avoid 100% churn\n",
        "current_date = transactions[\"Date\"].max() + pd.Timedelta(days=30)\n",
        "print(f\"\\nüìÖ Using reference date for churn: {current_date.date()}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 3Ô∏è‚É£ Customer Behavior (RFM + Lifecycle)\n",
        "# ------------------------------\n",
        "customer_behavior = transactions.groupby('Customer_ID').agg({\n",
        "    'Invoice_ID': 'nunique',\n",
        "    'Line_Total': ['sum','mean','std'],\n",
        "    'Date': ['min','max','count'],\n",
        "    'Product_ID': 'nunique',\n",
        "    'Store_ID': 'nunique',\n",
        "    'Discount': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "customer_behavior.columns = [\n",
        "    'total_orders','total_spent','avg_order_value','spending_std',\n",
        "    'first_purchase','last_purchase','total_transactions',\n",
        "    'unique_products_bought','unique_stores_visited','total_discount_used'\n",
        "]\n",
        "\n",
        "customer_behavior['days_since_last_purchase'] = (current_date - customer_behavior['last_purchase']).dt.days\n",
        "customer_behavior['days_as_customer'] = (customer_behavior['last_purchase'] - customer_behavior['first_purchase']).dt.days + 1\n",
        "customer_behavior['purchase_frequency_per_month'] = (\n",
        "    customer_behavior['total_orders'] / customer_behavior['days_as_customer'] * 30\n",
        ").round(2)\n",
        "\n",
        "# RFM scoring\n",
        "customer_behavior['recency_score'] = pd.qcut(customer_behavior['days_since_last_purchase'], 5, labels=[5,4,3,2,1], duplicates='drop')\n",
        "customer_behavior['frequency_score'] = pd.qcut(customer_behavior['total_orders'].rank(method='first'), 5, labels=[1,2,3,4,5], duplicates='drop')\n",
        "customer_behavior['monetary_score'] = pd.qcut(customer_behavior['total_spent'].rank(method='first'), 5, labels=[1,2,3,4,5], duplicates='drop')\n",
        "\n",
        "# Lifecycle stage\n",
        "customer_behavior['lifecycle_stage'] = 'Active'\n",
        "customer_behavior.loc[customer_behavior['total_orders'] == 1, 'lifecycle_stage'] = 'New'\n",
        "customer_behavior.loc[customer_behavior['days_since_last_purchase'] > 180, 'lifecycle_stage'] = 'At_Risk'\n",
        "customer_behavior.loc[customer_behavior['days_since_last_purchase'] > 365, 'lifecycle_stage'] = 'Churned'\n",
        "\n",
        "# Churn flag\n",
        "customer_behavior['is_churned'] = customer_behavior['lifecycle_stage'].isin(['At_Risk','Churned']).astype(int)\n",
        "\n",
        "# Value segment\n",
        "customer_behavior['customer_value_segment'] = pd.qcut(customer_behavior['total_spent'].rank(method='first'),\n",
        "                                                      3, labels=['Low_Value','Medium_Value','High_Value'],\n",
        "                                                      duplicates='drop')\n",
        "\n",
        "# ------------------------------\n",
        "# 4Ô∏è‚É£ Extend with demographics\n",
        "# ------------------------------\n",
        "customers[\"Date_Of_Birth\"] = pd.to_datetime(customers[\"Date_Of_Birth\"], errors='coerce')\n",
        "customers[\"Age\"] = (current_date.year - customers[\"Date_Of_Birth\"].dt.year).fillna(-1).astype(int)\n",
        "customers[\"AgeGroup\"] = pd.cut(customers[\"Age\"], bins=[0,25,40,60,100], labels=[\"<25\",\"25-40\",\"40-60\",\"60+\"], right=False)\n",
        "\n",
        "customer_features = customer_behavior.reset_index().merge(\n",
        "    customers[[\"Customer_ID\",\"Gender\",\"Country\",\"Age\",\"AgeGroup\"]],\n",
        "    on=\"Customer_ID\", how=\"left\"\n",
        ").set_index(\"Customer_ID\")\n",
        "\n",
        "# ------------------------------\n",
        "# 5Ô∏è‚É£ Category Affinity\n",
        "# ------------------------------\n",
        "df_cat = transactions.merge(products[[\"Product_ID\",\"Category\"]], on=\"Product_ID\", how=\"left\")\n",
        "cat_spend = df_cat.groupby([\"Customer_ID\",\"Category\"])[\"Line_Total\"].sum().unstack(fill_value=0)\n",
        "cat_spend[\"total\"] = cat_spend.sum(axis=1)\n",
        "for col in [\"Feminine\",\"Masculine\",\"Children\"]:\n",
        "    if col in cat_spend:\n",
        "        cat_spend[f\"pct_spend_{col.lower()}\"] = cat_spend[col] / cat_spend[\"total\"]\n",
        "cat_spend[\"top_category\"] = cat_spend[[\"Feminine\",\"Masculine\",\"Children\"]].idxmax(axis=1)\n",
        "\n",
        "customer_features = customer_features.join(cat_spend.filter(like=\"pct_spend\"))\n",
        "customer_features[\"top_category\"] = cat_spend[\"top_category\"]\n",
        "\n",
        "# ------------------------------\n",
        "# 6Ô∏è‚É£ Basket features\n",
        "# ------------------------------\n",
        "customer_features[\"avg_basket_size\"] = transactions.groupby(\"Customer_ID\")[\"Quantity\"].mean()\n",
        "customer_features[\"avg_basket_value\"] = (customer_features[\"total_spent\"] / customer_features[\"total_orders\"]).round(2)\n",
        "customer_features[\"basket_value_std\"] = transactions.groupby(\"Customer_ID\")[\"Line_Total\"].std()\n",
        "\n",
        "# ------------------------------\n",
        "# 7Ô∏è‚É£ Discount sensitivity\n",
        "# ------------------------------\n",
        "discounted_orders = transactions[transactions[\"Discount\"] > 0].groupby(\"Customer_ID\")[\"Invoice_ID\"].nunique()\n",
        "customer_features[\"pct_discounted_orders\"] = (discounted_orders / customer_features[\"total_orders\"]).fillna(0)\n",
        "customer_features[\"avg_discount_per_order\"] = (customer_features[\"total_discount_used\"] / customer_features[\"total_orders\"]).round(2)\n",
        "\n",
        "# ------------------------------\n",
        "# 8Ô∏è‚É£ Engagement over time\n",
        "# ------------------------------\n",
        "customer_features[\"avg_inter_purchase_gap\"] = (customer_features[\"days_as_customer\"] / customer_features[\"total_orders\"]).round(1)\n",
        "customer_features[\"purchase_trend\"] = ((customer_features[\"total_transactions\"] / customer_features[\"days_as_customer\"]) / customer_features[\"purchase_frequency_per_month\"]).round(2)\n",
        "\n",
        "# ------------------------------\n",
        "# 9Ô∏è‚É£ Store loyalty\n",
        "# ------------------------------\n",
        "store_counts = transactions.groupby([\"Customer_ID\",\"Store_ID\"])[\"Invoice_ID\"].count().reset_index()\n",
        "home_store = store_counts.loc[store_counts.groupby(\"Customer_ID\")[\"Invoice_ID\"].idxmax()]\n",
        "customer_features[\"home_store\"] = home_store.set_index(\"Customer_ID\")[\"Store_ID\"]\n",
        "customer_features[\"store_diversity\"] = (customer_features[\"unique_stores_visited\"] / customer_features[\"total_orders\"]).round(2)\n",
        "\n",
        "# ------------------------------\n",
        "# 1Ô∏è‚É£0Ô∏è‚É£ Save dataset\n",
        "# ------------------------------\n",
        "customer_features.to_csv(\"features_customers.csv\", index=True)\n",
        "print(\"\\n‚úÖ Customer features ready with churn target and all extended features!\")\n",
        "print(customer_features[['total_orders','total_spent','lifecycle_stage','is_churned']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5UvrEoC8V-k",
        "outputId": "dfa5c9cb-2587-46a2-b4e7-b8d40efced51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimizing transactions...\n",
            "‚úÖ Optimized transactions: 6,284,272 rows, 1147.85 MB (from 3249.16 MB)\n",
            "\n",
            "Optimizing customers...\n",
            "‚úÖ Optimized customers: 1,643,306 rows, 434.97 MB (from 804.98 MB)\n",
            "\n",
            "Optimizing products...\n",
            "‚úÖ Optimized products: 14,950 rows, 7.34 MB (from 11.33 MB)\n",
            "\n",
            "Optimizing stores...\n",
            "‚úÖ Optimized stores: 35 rows, 0.01 MB (from 0.01 MB)\n",
            "\n",
            "üìÖ Using reference date for churn: 2025-03-24\n",
            "\n",
            "‚úÖ Customer features ready with churn target and all extended features!\n",
            "             total_orders  total_spent lifecycle_stage  is_churned\n",
            "Customer_ID                                                       \n",
            "1                       2       158.28         Churned           1\n",
            "2                       5        763.0          Active           0\n",
            "3                       4        276.0          Active           0\n",
            "4                       5        177.0          Active           0\n",
            "5                       5       194.75         At_Risk           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 300)  # optional, adjust width\n",
        "\n",
        "# Display first few rows\n",
        "print(customer_features.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MioPM3u_lvK",
        "outputId": "8bea1f39-a695-4bf9-eca9-2a59f59f5507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             total_orders  total_spent  avg_order_value  spending_std      first_purchase       last_purchase  total_transactions  unique_products_bought  unique_stores_visited  total_discount_used  days_since_last_purchase  days_as_customer  purchase_frequency_per_month recency_score  \\\n",
            "Customer_ID                                                                                                                                                                                                                                                                                     \n",
            "1                       2       158.28            39.57         32.21 2023-03-09 18:45:00 2023-09-01 17:05:00                   4                       4                      1                  0.9                       570               176                          0.34             1   \n",
            "2                       5        763.0            69.36         39.94 2024-01-20 14:48:00 2025-02-16 12:38:00                  11                      11                      2                  0.0                        36               393                          0.38             5   \n",
            "3                       4        276.0             69.0         46.97 2023-09-22 15:51:00 2025-01-09 14:49:00                   4                       4                      1                  0.0                        74               475                          0.25             5   \n",
            "4                       5        177.0             35.4         39.64 2023-01-10 19:11:00 2025-02-02 13:20:00                   5                       4                      1                  0.0                        50               754                          0.20             5   \n",
            "5                       5       194.75            38.95         58.35 2023-04-26 18:01:00 2024-04-27 20:44:00                   5                       4                      1                  0.5                       331               368                          0.41             2   \n",
            "\n",
            "            frequency_score monetary_score lifecycle_stage  is_churned customer_value_segment Gender        Country  Age AgeGroup  pct_spend_feminine  pct_spend_masculine  pct_spend_children top_category  avg_basket_size  avg_basket_value  basket_value_std  pct_discounted_orders  \\\n",
            "Customer_ID                                                                                                                                                                                                                                                                               \n",
            "1                         2              3         Churned           1           Medium_Value      M  United States   19      <25            0.543341             0.076447            0.380212     Feminine              1.0             79.14         32.214607                    0.5   \n",
            "2                         4              5          Active           0             High_Value      M  United States   19      <25            0.098952             0.800786            0.100262    Masculine         1.363636             152.6         39.935004                    0.0   \n",
            "3                         4              4          Active           0           Medium_Value      M  United States   22      <25            0.155797             0.844203                 0.0    Masculine              1.5              69.0         46.968074                    0.0   \n",
            "4                         4              3          Active           0           Medium_Value      M  United States   18      <25            0.200565             0.799435                 0.0    Masculine              1.0              35.4         39.644356                    0.0   \n",
            "5                         4              3         At_Risk           1           Medium_Value      M  United States   27    25-40                 0.0             0.690629            0.309371    Masculine              1.0             38.95         58.346594                    0.2   \n",
            "\n",
            "             avg_discount_per_order  avg_inter_purchase_gap  purchase_trend  home_store  store_diversity  \n",
            "Customer_ID                                                                                               \n",
            "1                              0.45                    88.0            0.07           1             0.50  \n",
            "2                               0.0                    78.6            0.07           1             0.40  \n",
            "3                               0.0                   118.8            0.03           1             0.25  \n",
            "4                               0.0                   150.8            0.03           1             0.20  \n",
            "5                               0.1                    73.6            0.03           1             0.20  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 2: PRODUCT PERFORMANCE & CHARACTERISTICS\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" PART 2: PRODUCT PERFORMANCE & CHARACTERISTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Sales performance\n",
        "\n",
        "product_sales = transactions.groupby(\"Product_ID\").agg({\n",
        "    \"Line_Total\": [\"sum\", \"mean\", \"count\"],\n",
        "    \"Quantity\": \"sum\",\n",
        "    \"Unit_Price\": \"mean\",\n",
        "    \"Customer_ID\": \"nunique\",\n",
        "    \"Store_ID\": \"nunique\",\n",
        "    \"Date\": [\"min\", \"max\"]\n",
        "}).round(2)\n",
        "\n",
        "product_sales.columns = [\n",
        "    \"total_revenue\", \"avg_revenue_per_txn\", \"num_transactions\",\n",
        "    \"total_units_sold\", \"avg_unit_price\", \"unique_customers\",\n",
        "    \"num_stores\", \"first_sale_date\", \"last_sale_date\"\n",
        "]\n",
        "\n",
        "# Lifecycle\n",
        "product_sales[\"days_on_market\"] = (\n",
        "    product_sales[\"last_sale_date\"] - product_sales[\"first_sale_date\"]\n",
        ").dt.days + 1\n",
        "product_sales[\"sales_velocity\"] = (\n",
        "    product_sales[\"num_transactions\"] / product_sales[\"days_on_market\"] * 30\n",
        ").round(2)\n",
        "\n",
        "# 2. Merge product details\n",
        "\n",
        "products[\"Production_Cost\"] = pd.to_numeric(products[\"Production_Cost\"], errors=\"coerce\")\n",
        "\n",
        "product_features = (\n",
        "    product_sales.reset_index()\n",
        "    .merge(\n",
        "        products[[\"Product_ID\", \"Category\", \"Sub_Category\", \"Color\", \"Production_Cost\"]],\n",
        "        on=\"Product_ID\",\n",
        "        how=\"left\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# 3. Profitability\n",
        "\n",
        "product_features[\"profit_per_unit\"] = (\n",
        "    product_features[\"avg_unit_price\"] - product_features[\"Production_Cost\"]\n",
        ")\n",
        "product_features[\"profit_margin_pct\"] = (\n",
        "    product_features[\"profit_per_unit\"] / product_features[\"avg_unit_price\"] * 100\n",
        ").round(2)\n",
        "product_features[\"total_profit\"] = (\n",
        "    product_features[\"profit_per_unit\"] * product_features[\"total_units_sold\"]\n",
        ")\n",
        "\n",
        "# 4. Positioning & Popularity\n",
        "\n",
        "product_features[\"price_tier\"] = pd.qcut(\n",
        "    product_features[\"avg_unit_price\"],\n",
        "    q=3, labels=[\"Budget\", \"Mid_Range\", \"Premium\"], duplicates=\"drop\"\n",
        ")\n",
        "\n",
        "product_features[\"popularity_tier\"] = pd.qcut(\n",
        "    product_features[\"unique_customers\"].rank(method=\"first\"),\n",
        "    q=5, labels=[\"Niche\", \"Low\", \"Moderate\", \"Popular\", \"Best_Seller\"], duplicates=\"drop\"\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Product features created: {product_features.shape}\")\n",
        "print(product_features.head(3))\n"
      ],
      "metadata": {
        "id": "8tvyrL7PsviC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fca8207-376c-42be-c910-dc971c2bf7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " PART 2: PRODUCT PERFORMANCE & CHARACTERISTICS\n",
            "======================================================================\n",
            "‚úÖ Product features created: (14950, 21)\n",
            "   Product_ID  total_revenue  avg_revenue_per_txn  num_transactions  total_units_sold  avg_unit_price  unique_customers  num_stores     first_sale_date      last_sale_date  days_on_market  sales_velocity  Category           Sub_Category  Color  Production_Cost  profit_per_unit  profit_margin_pct  \\\n",
            "0           1       23210.82               145.07               160               168          166.51               150          33 2023-01-01 12:39:00 2023-03-15 00:00:00              73           65.75  Feminine      Coats and Blazers    NaN        23.450001       143.059999              85.92   \n",
            "1           2       18680.75               112.53               166               190          117.69               158          32 2023-01-01 00:00:00 2023-03-02 00:00:00              61           81.64  Feminine  Sweaters and Knitwear   PINK            24.35            93.34              79.31   \n",
            "2           3        18164.5               162.18               112               132          154.58               104          31 2023-01-01 08:53:00 2023-02-28 09:53:00              59           56.95  Feminine  Dresses and Jumpsuits  BLACK            33.57           121.01              78.28   \n",
            "\n",
            "   total_profit price_tier popularity_tier  \n",
            "0  24034.079872    Premium             Low  \n",
            "1  17734.599928  Mid_Range             Low  \n",
            "2   15973.32004    Premium           Niche  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 3: TEMPORAL & SEASONALITY FEATURES\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" PART 3: TEMPORAL & SEASONALITY FEATURES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Ensure datetime format\n",
        "transactions[\"Date\"] = pd.to_datetime(transactions[\"Date\"], errors=\"coerce\")\n",
        "\n",
        "# 1. Basic calendar features\n",
        "\n",
        "transactions[\"year\"] = transactions[\"Date\"].dt.year\n",
        "transactions[\"month\"] = transactions[\"Date\"].dt.month\n",
        "transactions[\"day\"] = transactions[\"Date\"].dt.day\n",
        "transactions[\"weekday\"] = transactions[\"Date\"].dt.dayofweek   # 0=Mon, 6=Sun\n",
        "transactions[\"weekday_name\"] = transactions[\"Date\"].dt.day_name()\n",
        "transactions[\"quarter\"] = transactions[\"Date\"].dt.quarter\n",
        "transactions[\"week_of_year\"] = transactions[\"Date\"].dt.isocalendar().week\n",
        "\n",
        "# 2. Seasonality\n",
        "\n",
        "season_map = {\n",
        "    12: \"Winter\", 1: \"Winter\", 2: \"Winter\",\n",
        "    3: \"Spring\", 4: \"Spring\", 5: \"Spring\",\n",
        "    6: \"Summer\", 7: \"Summer\", 8: \"Summer\",\n",
        "    9: \"Fall\", 10: \"Fall\", 11: \"Fall\"\n",
        "}\n",
        "transactions[\"season\"] = transactions[\"month\"].map(season_map)\n",
        "\n",
        "# 3. Business calendar flags\n",
        "\n",
        "transactions[\"is_weekend\"] = transactions[\"weekday\"].isin([5, 6]).astype(int)\n",
        "transactions[\"is_month_start\"] = (transactions[\"day\"] <= 5).astype(int)\n",
        "transactions[\"is_month_end\"] = (transactions[\"day\"] >= 25).astype(int)\n",
        "\n",
        "# 4. Key holidays (rough estimates)\n",
        "\n",
        "transactions[\"is_holiday_season\"] = transactions[\"month\"].isin([11, 12]).astype(int)\n",
        "transactions[\"is_new_year\"] = (transactions[\"month\"] == 1).astype(int)\n",
        "transactions[\"is_valentine\"] = ((transactions[\"month\"] == 2) & (transactions[\"day\"].between(10, 20))).astype(int)\n",
        "transactions[\"is_back_to_school\"] = (\n",
        "    (transactions[\"month\"] == 8) | ((transactions[\"month\"] == 9) & (transactions[\"day\"] <= 15))\n",
        ").astype(int)\n",
        "\n",
        "print(\"‚úÖ Temporal features added:\",\n",
        "      [col for col in transactions.columns if col in [\n",
        "          \"year\",\"month\",\"day\",\"weekday\",\"weekday_name\",\"quarter\",\"week_of_year\",\n",
        "          \"season\",\"is_weekend\",\"is_month_start\",\"is_month_end\",\n",
        "          \"is_holiday_season\",\"is_new_year\",\"is_valentine\",\"is_back_to_school\"\n",
        "      ]])\n",
        "print(f\"‚úÖ Temporal features created: {transactions.shape}\")\n",
        "print(transactions.head(3))\n"
      ],
      "metadata": {
        "id": "HntRvTV_s3Pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f6a38e-1c24-459e-f98a-8a588cbe7a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " PART 3: TEMPORAL & SEASONALITY FEATURES\n",
            "======================================================================\n",
            "‚úÖ Temporal features added: ['year', 'month', 'day', 'weekday', 'weekday_name', 'quarter', 'week_of_year', 'season', 'is_weekend', 'is_month_start', 'is_month_end', 'is_holiday_season', 'is_new_year', 'is_valentine', 'is_back_to_school']\n",
            "‚úÖ Temporal features created: (6284272, 35)\n",
            "   Transaction_ID           Invoice_ID  Line  Customer_ID  Product_ID Size   Color  Unit_Price  Quantity                Date  Discount  Line_Total  Store_ID  Employee_ID Currency Currency_Symbol                SKU Transaction_Type Payment_Method  Invoice_Total  year  month  day  weekday  \\\n",
            "0               1  INV-US-001-01628272     1        42813        2025    M  YELLOW        36.5         1 2023-01-01 19:46:00       0.4        21.9         1           11      USD               $  CHCO2025-M-YELLOW             Sale    Credit Card           21.9  2023      1    1        6   \n",
            "1               2  INV-US-001-01628273     1        19756        2794    L  YELLOW        49.5         2 2023-01-01 12:02:00       0.4        59.4         1           10      USD               $  MACO2794-L-YELLOW             Sale    Credit Card           59.4  2023      1    1        6   \n",
            "2               3  INV-US-001-01628274     1        20648         272    M    PINK        49.5         1 2023-01-01 16:59:00       0.4        29.7         1            5      USD               $     MACO272-M-PINK             Sale           Cash           29.7  2023      1    1        6   \n",
            "\n",
            "  weekday_name  quarter  week_of_year  season  is_weekend  is_month_start  is_month_end  is_holiday_season  is_new_year  is_valentine  is_back_to_school  \n",
            "0       Sunday        1            52  Winter           1               1             0                  0            1             0                  0  \n",
            "1       Sunday        1            52  Winter           1               1             0                  0            1             0                  0  \n",
            "2       Sunday        1            52  Winter           1               1             0                  0            1             0                  0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 4: STORE & GEOGRAPHIC FEATURES\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" PART 4: STORE & GEOGRAPHIC FEATURES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Store size categories\n",
        "stores['store_size'] = pd.qcut(\n",
        "    stores['Number_of_Employees'],\n",
        "    q=3, labels=['Small', 'Medium', 'Large'], duplicates='drop'\n",
        ")\n",
        "\n",
        "# Economic indicators by country (simplified but realistic)\n",
        "country_metrics = {\n",
        "    'United States': {'gdp_per_capita': 65000, 'fashion_index': 85, 'market_maturity': 'Mature'},\n",
        "    '‰∏≠ÂõΩ': {'gdp_per_capita': 12000, 'fashion_index': 78, 'market_maturity': 'Growing'},\n",
        "    'Deutschland': {'gdp_per_capita': 48000, 'fashion_index': 92, 'market_maturity': 'Mature'},\n",
        "    'France': {'gdp_per_capita': 43000, 'fashion_index': 95, 'market_maturity': 'Mature'},\n",
        "    'Espa√±a': {'gdp_per_capita': 30000, 'fashion_index': 80, 'market_maturity': 'Mature'},\n",
        "    'United Kingdom': {'gdp_per_capita': 42000, 'fashion_index': 88, 'market_maturity': 'Mature'},\n",
        "    'Portugal': {'gdp_per_capita': 25000, 'fashion_index': 75, 'market_maturity': 'Growing'}\n",
        "}\n",
        "\n",
        "# Add to stores\n",
        "for country, metrics in country_metrics.items():\n",
        "    stores.loc[stores['Country'] == country, 'gdp_per_capita'] = metrics['gdp_per_capita']\n",
        "    stores.loc[stores['Country'] == country, 'fashion_index'] = metrics['fashion_index']\n",
        "    stores.loc[stores['Country'] == country, 'market_maturity'] = metrics['market_maturity']\n",
        "\n",
        "# Store performance\n",
        "store_performance = transactions.groupby('Store_ID').agg({\n",
        "    'Line_Total': 'sum',\n",
        "    'Invoice_ID': 'nunique',\n",
        "    'Customer_ID': 'nunique'\n",
        "}).round(2)\n",
        "store_performance.columns = ['store_total_revenue', 'store_total_orders', 'store_unique_customers']\n",
        "\n",
        "stores = stores.merge(store_performance.reset_index(), on='Store_ID', how='left')\n",
        "stores['revenue_per_employee'] = (stores['store_total_revenue'] / stores['Number_of_Employees']).round(2)\n",
        "\n",
        "print(f\"‚úÖ Store features created: {stores.shape}\")\n",
        "print(stores.head(3))\n"
      ],
      "metadata": {
        "id": "GXtFFUpus4j5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e0c0114-69dc-4e7a-b3d2-289b29c2396f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " PART 4: STORE & GEOGRAPHIC FEATURES\n",
            "======================================================================\n",
            "‚úÖ Store features created: (35, 16)\n",
            "   Store_ID        Country         City         Store_Name  Number_of_Employees ZIP_Code   Latitude   Longitude store_size  gdp_per_capita  fashion_index market_maturity  store_total_revenue  store_total_orders  store_unique_customers  revenue_per_employee\n",
            "0         1  United States     New York     Store New York                    8    10001  40.712799  -74.005997      Small         65000.0           85.0          Mature          23791932.49              378882                  107047            2973991.56\n",
            "1         2  United States  Los Angeles  Store Los Angeles                    7    90001    34.0522 -118.243698      Small         65000.0           85.0          Mature          17966592.86              285543                   89791            2566656.12\n",
            "2         3  United States      Chicago      Store Chicago                    8    60601  41.878101  -87.629799      Small         65000.0           85.0          Mature           9060508.66              144196                   62449            1132563.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 5: INTERACTION & PREFERENCE FEATURES (Memory-Safe)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" PART 5: INTERACTION & PREFERENCE FEATURES (Optimized)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Customer preferred category (spend-based)\n",
        "cust_cat_spend = (\n",
        "    transactions.merge(products[[\"Product_ID\", \"Category\"]], on=\"Product_ID\")\n",
        "    .groupby([\"Customer_ID\", \"Category\"])[\"Line_Total\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Only keep the TOP category per customer\n",
        "customer_pref_category = (\n",
        "    cust_cat_spend.loc[cust_cat_spend.groupby(\"Customer_ID\")[\"Line_Total\"].idxmax()]\n",
        "    [[\"Customer_ID\", \"Category\"]]\n",
        "    .rename(columns={\"Category\": \"preferred_category\"})\n",
        ")\n",
        "\n",
        "# 2. Customer preferred store\n",
        "cust_store_visits = (\n",
        "    transactions.groupby([\"Customer_ID\", \"Store_ID\"])[\"Invoice_ID\"]\n",
        "    .count()\n",
        "    .reset_index(name=\"visit_count\")\n",
        ")\n",
        "\n",
        "customer_primary_store = (\n",
        "    cust_store_visits.loc[cust_store_visits.groupby(\"Customer_ID\")[\"visit_count\"].idxmax()]\n",
        "    [[\"Customer_ID\", \"Store_ID\"]]\n",
        "    .rename(columns={\"Store_ID\": \"primary_store_id\"})\n",
        ")\n",
        "\n",
        "# 3. Price sensitivity (no wide pivot, just aggregates)\n",
        "customer_price = transactions.groupby(\"Customer_ID\").agg(\n",
        "    avg_price_point=(\"Unit_Price\", \"mean\"),\n",
        "    price_variance=(\"Unit_Price\", \"std\"),\n",
        "    avg_discount_value=(\"Discount\", \"mean\"),\n",
        "    total_discounts_claimed=(\"Discount\", \"sum\"),\n",
        ").round(2)\n",
        "\n",
        "customer_price[\"price_sensitivity_score\"] = (\n",
        "    (customer_price[\"avg_discount_value\"] / customer_price[\"avg_price_point\"]) * 100\n",
        ").round(2)\n",
        "\n",
        "print(f\"‚úÖ Interaction features merged. Final shape: {customer_features.shape}\")\n",
        "print(customer_features.head(3))"
      ],
      "metadata": {
        "id": "aSWD4O_ns9tA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14a2510-0e75-4a47-bb15-2d9becccc2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " PART 5: INTERACTION & PREFERENCE FEATURES (Optimized)\n",
            "======================================================================\n",
            "‚úÖ Interaction features merged. Final shape: (1268571, 36)\n",
            "             total_orders  total_spent  avg_order_value  spending_std      first_purchase       last_purchase  total_transactions  unique_products_bought  unique_stores_visited  total_discount_used  days_since_last_purchase  days_as_customer  purchase_frequency_per_month recency_score  \\\n",
            "Customer_ID                                                                                                                                                                                                                                                                                     \n",
            "1                       2       158.28            39.57         32.21 2023-03-09 18:45:00 2023-09-01 17:05:00                   4                       4                      1                  0.9                       570               176                          0.34             1   \n",
            "2                       5        763.0            69.36         39.94 2024-01-20 14:48:00 2025-02-16 12:38:00                  11                      11                      2                  0.0                        36               393                          0.38             5   \n",
            "3                       4        276.0             69.0         46.97 2023-09-22 15:51:00 2025-01-09 14:49:00                   4                       4                      1                  0.0                        74               475                          0.25             5   \n",
            "\n",
            "            frequency_score monetary_score lifecycle_stage  is_churned customer_value_segment Gender        Country  Age AgeGroup  pct_spend_feminine  pct_spend_masculine  pct_spend_children top_category  avg_basket_size  avg_basket_value  basket_value_std  pct_discounted_orders  \\\n",
            "Customer_ID                                                                                                                                                                                                                                                                               \n",
            "1                         2              3         Churned           1           Medium_Value      M  United States   19      <25            0.543341             0.076447            0.380212     Feminine              1.0             79.14         32.214607                    0.5   \n",
            "2                         4              5          Active           0             High_Value      M  United States   19      <25            0.098952             0.800786            0.100262    Masculine         1.363636             152.6         39.935004                    0.0   \n",
            "3                         4              4          Active           0           Medium_Value      M  United States   22      <25            0.155797             0.844203                 0.0    Masculine              1.5              69.0         46.968074                    0.0   \n",
            "\n",
            "             avg_discount_per_order  avg_inter_purchase_gap  purchase_trend  home_store  store_diversity  \n",
            "Customer_ID                                                                                               \n",
            "1                              0.45                    88.0            0.07           1             0.50  \n",
            "2                               0.0                    78.6            0.07           1             0.40  \n",
            "3                               0.0                   118.8            0.03           1             0.25  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# 1Ô∏è‚É£ Prepare Customer Features for Merge\n",
        "# ================================================================\n",
        "# Select only relevant customer-level features for transactions\n",
        "customer_merge_cols = [\n",
        "    'Customer_ID', 'Age', 'AgeGroup', 'Gender', 'Country',\n",
        "    'lifecycle_stage', 'customer_value_segment',\n",
        "    'top_category', 'avg_basket_value', 'purchase_frequency_per_month'\n",
        "]\n",
        "\n",
        "customer_features_subset = customer_features.reset_index()[customer_merge_cols]\n",
        "\n",
        "# ================================================================\n",
        "# 2Ô∏è‚É£ Merge Customer Features into Transactions\n",
        "# ================================================================\n",
        "ml_transactions = transactions.merge(\n",
        "    customer_features_subset,\n",
        "    on='Customer_ID',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# ================================================================\n",
        "# 3Ô∏è‚É£ Merge Product Features into Transactions\n",
        "# ================================================================\n",
        "product_merge_cols = [\n",
        "    'Product_ID', 'Category', 'Sub_Category', 'profit_per_unit',\n",
        "    'profit_margin_pct', 'price_tier', 'popularity_tier'\n",
        "]\n",
        "\n",
        "ml_transactions = ml_transactions.merge(\n",
        "    product_features[product_merge_cols],\n",
        "    on='Product_ID',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# ================================================================\n",
        "# 4Ô∏è‚É£ Merge Store Features into Transactions\n",
        "# ================================================================\n",
        "store_merge_cols = [\n",
        "    'Store_ID', 'Country', 'City', 'store_size', 'gdp_per_capita',\n",
        "    'fashion_index', 'revenue_per_employee'\n",
        "]\n",
        "\n",
        "ml_transactions = ml_transactions.merge(\n",
        "    stores[store_merge_cols],\n",
        "    on='Store_ID',\n",
        "    how='left',\n",
        "    suffixes=('_customer', '_store')\n",
        ")\n",
        "\n",
        "# ================================================================\n",
        "# 5Ô∏è‚É£ Sanity Checks\n",
        "# ================================================================\n",
        "print(\"üîé Merge integrity checks:\")\n",
        "print(\"Missing Customer_ID:\", ml_transactions['Customer_ID'].isna().sum())\n",
        "print(\"Missing Product_ID:\", ml_transactions['Product_ID'].isna().sum())\n",
        "print(\"Missing Store_ID:\", ml_transactions['Store_ID'].isna().sum())\n",
        "\n",
        "print(f\"\\n‚úÖ Final ML transaction dataset shape: {ml_transactions.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBfg9lBIiCUm",
        "outputId": "e8450ce9-795b-40ee-8e65-48052a5ea241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîé Merge integrity checks:\n",
            "Missing Customer_ID: 0\n",
            "Missing Product_ID: 0\n",
            "Missing Store_ID: 0\n",
            "\n",
            "‚úÖ Final ML transaction dataset shape: (6284272, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 7: SAVE DATASETS\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üíæ PART 7: SAVING FEATURE-ENGINEERED DATASETS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save all feature sets\n",
        "customer_features.to_csv('features_customers.csv', index=False)\n",
        "product_features.to_csv('features_products.csv', index=False)\n",
        "stores.to_csv('features_stores.csv', index=False)\n",
        "ml_transactions.to_csv('ml_ready_transactions.csv', index=False)\n",
        "\n",
        "print(\"‚úÖ Saved 4 feature-engineered datasets:\")\n",
        "print(\"   1. features_customers.csv - Customer demographics & behavior\")\n",
        "print(\"   2. features_products.csv - Product performance & characteristics\")\n",
        "print(\"   3. features_stores.csv - Store operations & geography\")\n",
        "print(\"   4. ml_ready_transactions.csv - Complete transaction dataset with all features\")\n",
        "\n",
        "# ================================================================\n",
        "# PART 8: FEATURE SUMMARY\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä FEATURE ENGINEERING SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüéØ CUSTOMER FEATURES (Total columns: {})\".format(len(customer_features.columns)))\n",
        "print(\"   Demographics: age, age_group, Gender, Country, City, Job Title\")\n",
        "print(\"   Behavioral: total_orders, total_spent, purchase_frequency, recency\")\n",
        "print(\"   Segments: lifecycle_stage, customer_value_segment, RFM scores\")\n",
        "print(\"   Preferences: preferred_category, primary_store_id, price_sensitivity\")\n",
        "\n",
        "print(\"\\nüõçÔ∏è PRODUCT FEATURES (Total columns: {})\".format(len(product_features.columns)))\n",
        "print(\"   Performance: total_revenue, units_sold, sales_velocity\")\n",
        "print(\"   Pricing: price_tier, profit_margin, avg_unit_price\")\n",
        "print(\"   Popularity: unique_customers, popularity_tier\")\n",
        "print(\"   Attributes: Category, Sub Category, Color\")\n",
        "\n",
        "print(\"\\nüìÖ TEMPORAL FEATURES\")\n",
        "print(\"   Time: year, month, quarter, week, day_of_week\")\n",
        "print(\"   Seasonality: season, is_weekend, is_holiday_season\")\n",
        "print(\"   Events: is_valentine, is_back_to_school, is_month_end\")\n",
        "\n",
        "print(\"\\nüè¨ STORE FEATURES (Total columns: {})\".format(len(stores.columns)))\n",
        "print(\"   Location: Country, City, gdp_per_capita, market_maturity\")\n",
        "print(\"   Operations: store_size, revenue_per_employee, fashion_index\")\n",
        "print(\"   Performance: store_total_revenue, store_unique_customers\")\n",
        "\n",
        "print(\"\\nüîó INTERACTION FEATURES\")\n",
        "print(\"   Customer-Product: preferred_category\")\n",
        "print(\"   Customer-Store: primary_store_id, unique_stores_visited\")\n",
        "print(\"   Price Behavior: price_sensitivity_score, avg_discount_rate\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üöÄ FEATURE ENGINEERING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n‚úÖ YOU NOW HAVE:\")\n",
        "print(\"   ‚Ä¢ {} customer features ready for segmentation & churn prediction\".format(len(customer_features.columns)))\n",
        "print(\"   ‚Ä¢ {} product features ready for recommendation systems\".format(len(product_features.columns)))\n",
        "print(\"   ‚Ä¢ {} temporal features ready for sales forecasting\".format(8))\n",
        "print(\"   ‚Ä¢ {} geographic features ready for expansion analysis\".format(3))\n",
        "print(\"   ‚Ä¢ Complete ML dataset with {} rows and {} columns\".format(len(ml_transactions), len(ml_transactions.columns)))\n",
        "\n",
        "print(\"\\nüí° NEXT STEPS - Choose Your ML Model:\")\n",
        "print(\"   1. Customer Churn Prediction (using lifecycle_stage + RFM)\")\n",
        "print(\"   2. Sales Forecasting (using temporal + store + product features)\")\n",
        "print(\"   3. Customer Segmentation (using all customer features)\")\n",
        "print(\"   4. Product Recommendation (using preferred_category + purchase history)\")\n",
        "print(\"   5. Dynamic Pricing (using price_sensitivity + market features)\")\n",
        "\n",
        "print(\"\\nüéØ Ready to build impressive ML models that drive business decisions!\")"
      ],
      "metadata": {
        "id": "h56zMygqtObH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9286ea-2f9e-444d-e8d9-a4308e171747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üíæ PART 7: SAVING FEATURE-ENGINEERED DATASETS\n",
            "======================================================================\n",
            "‚úÖ Saved 4 feature-engineered datasets:\n",
            "   1. features_customers.csv - Customer demographics & behavior\n",
            "   2. features_products.csv - Product performance & characteristics\n",
            "   3. features_stores.csv - Store operations & geography\n",
            "   4. ml_ready_transactions.csv - Complete transaction dataset with all features\n",
            "\n",
            "======================================================================\n",
            "üìä FEATURE ENGINEERING SUMMARY\n",
            "======================================================================\n",
            "\n",
            "üéØ CUSTOMER FEATURES (Total columns: 36)\n",
            "   Demographics: age, age_group, Gender, Country, City, Job Title\n",
            "   Behavioral: total_orders, total_spent, purchase_frequency, recency\n",
            "   Segments: lifecycle_stage, customer_value_segment, RFM scores\n",
            "   Preferences: preferred_category, primary_store_id, price_sensitivity\n",
            "\n",
            "üõçÔ∏è PRODUCT FEATURES (Total columns: 21)\n",
            "   Performance: total_revenue, units_sold, sales_velocity\n",
            "   Pricing: price_tier, profit_margin, avg_unit_price\n",
            "   Popularity: unique_customers, popularity_tier\n",
            "   Attributes: Category, Sub Category, Color\n",
            "\n",
            "üìÖ TEMPORAL FEATURES\n",
            "   Time: year, month, quarter, week, day_of_week\n",
            "   Seasonality: season, is_weekend, is_holiday_season\n",
            "   Events: is_valentine, is_back_to_school, is_month_end\n",
            "\n",
            "üè¨ STORE FEATURES (Total columns: 16)\n",
            "   Location: Country, City, gdp_per_capita, market_maturity\n",
            "   Operations: store_size, revenue_per_employee, fashion_index\n",
            "   Performance: store_total_revenue, store_unique_customers\n",
            "\n",
            "üîó INTERACTION FEATURES\n",
            "   Customer-Product: preferred_category\n",
            "   Customer-Store: primary_store_id, unique_stores_visited\n",
            "   Price Behavior: price_sensitivity_score, avg_discount_rate\n",
            "\n",
            "======================================================================\n",
            "üöÄ FEATURE ENGINEERING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "‚úÖ YOU NOW HAVE:\n",
            "   ‚Ä¢ 36 customer features ready for segmentation & churn prediction\n",
            "   ‚Ä¢ 21 product features ready for recommendation systems\n",
            "   ‚Ä¢ 8 temporal features ready for sales forecasting\n",
            "   ‚Ä¢ 3 geographic features ready for expansion analysis\n",
            "   ‚Ä¢ Complete ML dataset with 6284272 rows and 56 columns\n",
            "\n",
            "üí° NEXT STEPS - Choose Your ML Model:\n",
            "   1. Customer Churn Prediction (using lifecycle_stage + RFM)\n",
            "   2. Sales Forecasting (using temporal + store + product features)\n",
            "   3. Customer Segmentation (using all customer features)\n",
            "   4. Product Recommendation (using preferred_category + purchase history)\n",
            "   5. Dynamic Pricing (using price_sensitivity + market features)\n",
            "\n",
            "üéØ Ready to build impressive ML models that drive business decisions!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcb580e1",
        "outputId": "3fadae48-0c7f-4f06-f846-47f7d1a8d322"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6c96a59",
        "outputId": "3304e0db-4cc1-4aed-be79-ade9c8958a1a"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path where you want to save the files in your Google Drive\n",
        "drive_path = '/content/drive/MyDrive/feature_engineered_data'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# List of files to save\n",
        "files_to_save = [\n",
        "    'features_customers.csv',\n",
        "    'features_products.csv',\n",
        "    'features_stores.csv',\n",
        "    'ml_ready_transactions.csv'\n",
        "]\n",
        "\n",
        "print(f\"Saving files to {drive_path}...\")\n",
        "\n",
        "for filename in files_to_save:\n",
        "    source_path = filename\n",
        "    destination_path = os.path.join(drive_path, filename)\n",
        "    # Check if the file exists in the current directory before copying\n",
        "    if os.path.exists(source_path):\n",
        "        !cp \"{source_path}\" \"{destination_path}\"\n",
        "        print(f\"‚úÖ Saved {filename} to Google Drive.\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Warning: {filename} not found in current directory. Skipping.\")\n",
        "\n",
        "print(\"\\nAll specified files have been copied to your Google Drive.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving files to /content/drive/MyDrive/feature_engineered_data...\n",
            "‚úÖ Saved features_customers.csv to Google Drive.\n",
            "‚úÖ Saved features_products.csv to Google Drive.\n",
            "‚úÖ Saved features_stores.csv to Google Drive.\n",
            "‚úÖ Saved ml_ready_transactions.csv to Google Drive.\n",
            "\n",
            "All specified files have been copied to your Google Drive.\n"
          ]
        }
      ]
    }
  ]
}